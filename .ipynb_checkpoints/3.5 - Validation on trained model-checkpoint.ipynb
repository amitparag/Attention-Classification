{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c88f363-b0dd-43c9-b58c-1ec6ad8112ba",
   "metadata": {},
   "source": [
    "### Let us check the trained model - checkpoint_epoch250.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29c39450-4932-4181-a4a4-defb2cc6c70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from vit_pytorch.vivit import ViT\n",
    "from training import VideoDataset, data_transform\n",
    "torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80fe8358-1400-49f6-96e0-93eb88cc7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "        image_size = (240,320),          # image size\n",
    "        frames = 450,                    # number of frames\n",
    "        image_patch_size = (80,80),      # image patch size\n",
    "        frame_patch_size = 45,           # frame patch size\n",
    "        num_classes = 2,\n",
    "        dim = 64,\n",
    "        spatial_depth = 3,               # depth of the spatial transformer\n",
    "        temporal_depth = 3,              # depth of the temporal transformer\n",
    "        heads = 4,\n",
    "        mlp_dim = 126\n",
    "    )\n",
    "\n",
    "\n",
    "checkpoint_folder = './checkpoints'\n",
    "\n",
    "checkpoint_files = './checkpoints/checkpoint_epoch250.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5afff3c-a55d-476c-b17b-6f7eaaba96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir    = './dataset/learning'\n",
    "val_dir     = os.path.join(root_dir, 'validation')\n",
    "val_dataset     = VideoDataset(val_dir, transform=data_transform)\n",
    "\n",
    "batch_size      = 1\n",
    "\n",
    "validation_dataloader   = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13d6ee9-36b9-4125-be96-c2bac7b397ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 0, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 1, Actual Class 1\n",
      "Predicted Class 0, Actual Class 0\n",
      "Predicted Class 1, Actual Class 1\n",
      "Validation Loss: 0.5481\n",
      "Validation Accuracy: 96.20%\n"
     ]
    }
   ],
   "source": [
    "validation_losses = []\n",
    "validation_accuracy = []\n",
    "epochs = []\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint  = torch.load(checkpoint_files)\n",
    "checkpoint_epochs = checkpoint['epoch']\n",
    "\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of accuracy and loss\n",
    "total_samples = 0\n",
    "correct_predictions = 0\n",
    "total_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_dataloader:\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        print(f\"Predicted Class {predicted.item()}, Actual Class {labels.item()}\")\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Calculate accuracy and loss\n",
    "accuracy = correct_predictions / total_samples\n",
    "average_loss = total_loss / len(validation_dataloader)\n",
    "epochs.append(checkpoint_epochs)\n",
    "validation_losses.append(average_loss)\n",
    "validation_accuracy.append(accuracy)\n",
    "print(f\"Validation Loss: {average_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c0ead-0eff-492b-a768-27aeff1162a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
