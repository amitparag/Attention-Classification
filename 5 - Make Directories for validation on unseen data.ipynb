{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555a45cb-1873-43fb-9148-96ec317df4f6",
   "metadata": {},
   "source": [
    "### Let's create validation dataloaders for unseen objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa7f97e5-c9d9-44dc-a295-87a02391d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_video\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from training import VideoDataset, data_transform\n",
    "\n",
    "from vit_pytorch.vivit import ViT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e9fb17-d92f-4754-803f-f8e6962a29dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_validation_data_dir = './dataset/unseen_data'\n",
    "slip_dir                 = os.path.join(root_validation_data_dir, 'slip')\n",
    "wriggle_dir              = os.path.join(root_validation_data_dir, 'wriggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b639aa-b24c-458c-887b-8d56f4d90488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create 'slip' and 'wriggle' directories if they don't exist\n",
    "os.makedirs(slip_dir, exist_ok=True)\n",
    "os.makedirs(wriggle_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cfe86cb-4742-4bcb-9180-2132ba5e318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_or_move_with_uuid(src, dst, is_copy=True):\n",
    "    unique_filename = str(uuid.uuid4()) + os.path.splitext(src)[-1]\n",
    "    destination_path = os.path.join(dst, unique_filename)\n",
    "    if is_copy:\n",
    "        shutil.copy(src, destination_path)\n",
    "    else:\n",
    "        shutil.move(src, destination_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61627abf-09d1-4fbb-9db4-03c8d33b35a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing complete.\n"
     ]
    }
   ],
   "source": [
    "# Recursively search for \"left.avi\" and \"right.avi\" files in base_data_dir\n",
    "for root, _, files in os.walk(root_validation_data_dir):\n",
    "    if \"left.avi\" in files or \"right.avi\" in files:\n",
    "        if \"slip.txt\" in files:\n",
    "            \n",
    "            # Copy \"left.avi\" and \"right.avi\" to 'slip' directory\n",
    "            copy_or_move_with_uuid(os.path.join(root, \"left.avi\"), slip_dir, is_copy=True)\n",
    "            copy_or_move_with_uuid(os.path.join(root, \"right.avi\"), slip_dir, is_copy=True)\n",
    "        else:\n",
    "            # Move \"left.avi\" and \"right.avi\" to 'wriggle' directory\n",
    "            copy_or_move_with_uuid(os.path.join(root, \"left.avi\"), wriggle_dir, is_copy=True)\n",
    "            copy_or_move_with_uuid(os.path.join(root, \"right.avi\"), wriggle_dir, is_copy=True)\n",
    "            #print(\"wriggle\",files)\n",
    "print(\"Organizing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f5baa7-ea02-4fde-a865-6dd5409e52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets():\n",
    "\n",
    "    \n",
    "    root_dir = './dataset/unseen_data'\n",
    "    source_slip_videos = './dataset/unseen_data/slip'  \n",
    "    source_wriggle_videos = './dataset/unseen_data/wriggle' \n",
    "    \n",
    "    classes = ['slip', 'wriggle']\n",
    "    subsets = ['validation']\n",
    "    split_ratios = [1.0]  # Train, validation, test split ratios\n",
    "    \n",
    "    # Create root directory\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "    \n",
    "    # Create subsets directories and copy videos\n",
    "    for subset in subsets:\n",
    "        subset_dir = os.path.join(root_dir, subset)\n",
    "        if not os.path.exists(subset_dir):\n",
    "            os.makedirs(subset_dir)\n",
    "    \n",
    "        for class_name in classes:\n",
    "            class_dir = os.path.join(subset_dir, class_name)\n",
    "            if not os.path.exists(class_dir):\n",
    "                os.makedirs(class_dir)\n",
    "            \n",
    "            source_videos = source_slip_videos if class_name == 'slip' else source_wriggle_videos\n",
    "            video_files = [f for f in os.listdir(source_videos) if f.endswith('.avi')]\n",
    "            random.shuffle(video_files)  # Shuffle video files\n",
    "            \n",
    "            split_ratio = split_ratios[subsets.index(subset)]\n",
    "            num_videos = int(len(video_files) * split_ratio)\n",
    "            \n",
    "            for video_file in video_files[:num_videos]:\n",
    "                src_path = os.path.join(source_videos, video_file)\n",
    "                dest_path = os.path.join(class_dir, video_file)\n",
    "                shutil.copy(src_path, dest_path)\n",
    "    \n",
    "    print(\"Directory structure and video copying completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea01a4c-d1d1-4fe5-9439-d537e76d9f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure and video copying completed.\n"
     ]
    }
   ],
   "source": [
    "make_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8d2c63e-b386-40c6-bdce-873f8c0dead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.videos = self._load_videos()\n",
    "        self.transform = transform\n",
    "\n",
    "    def _load_videos(self):\n",
    "        videos = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            for video_file in os.listdir(class_dir):\n",
    "                if video_file.endswith('.avi'):\n",
    "                    video_path = os.path.join(class_dir, video_file)\n",
    "                    videos.append((video_path, self.class_to_idx[class_name]))\n",
    "        return videos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.videos[idx]\n",
    "\n",
    "        video = imageio.get_reader(video_path, 'ffmpeg')  # Open video with imageio\n",
    "        \n",
    "        #print(\"Video:\", video_path)\n",
    "        #print(\"Number of frames:\", len(video))\n",
    "        #print(\"Height:\", video.get_meta_data()[\"size\"][1])\n",
    "        #print(\"Width:\", video.get_meta_data()[\"size\"][0])\n",
    "        \n",
    "        \n",
    "        frames = []\n",
    "        \n",
    "        for frame in video:\n",
    "            frame = frame[:, :, :3]  # Keep only the first three channels (RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "        video.close()\n",
    "        \n",
    "        #container = av.open(video_path)  # Open the video file with pyav\n",
    "        #frames = []\n",
    "        #for frame in container.decode(video=0):  # Loop through video frames\n",
    "        #    img = frame.to_image()\n",
    "        #    img = img.convert('RGB')  # Convert to RGB format\n",
    "        #    frame_array = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).view(img.size[1], img.size[0], 3)\n",
    "        #    frames.append(frame_array.numpy())\n",
    "        \n",
    "        #container.close() \n",
    "        \n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "            video_tensor = torch.stack(frames)\n",
    "        #print(video_tensor.shape)\n",
    "        return video_tensor.permute(1, 0, 2, 3), label  # Permute to (batch, channels, frames, height, width)\n",
    "\n",
    "data_transform = Compose([\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8225b2b-e59c-482c-9d01-a4b3100ca9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_data_dir = os.path.join(root_validation_data_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e220eb29-23c1-4ace-8f4e-f666e4dfe302",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = VideoDataset(validation_data_dir, transform=data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6a29849-4c35-4657-b376-258c75e0fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, num_workers=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a010da5-159c-4ff7-9dca-4cbffdb2b3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slip', 'wriggle']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loader.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c49e92-7895-4ecb-b5e0-2ada2d99f97d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
