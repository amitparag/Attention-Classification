{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ed09af-1062-4712-9e42-5566dd210869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "import av\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_video\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33194a2a-5531-409b-8fb5-8aa747c19b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd10ee7c-5fb5-4296-a3e0-e9fffc6ee747",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc73a4f-f73d-42d1-a14c-ef381bcc5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67bf5753-e1b3-43d3-91c6-d3e175d48c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets():\n",
    "\n",
    "    \n",
    "    root_dir = './dataset'\n",
    "    source_slip_videos = './dataset/slip'  \n",
    "    source_wriggle_videos = './dataset/wriggle' \n",
    "    \n",
    "    classes = ['slip', 'wriggle']\n",
    "    subsets = ['train', 'validation', 'test']\n",
    "    split_ratios = [0.7, 0.15, 0.15]  # Train, validation, test split ratios\n",
    "    \n",
    "    # Create root directory\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.makedirs(root_dir)\n",
    "    \n",
    "    # Create subsets directories and copy videos\n",
    "    for subset in subsets:\n",
    "        subset_dir = os.path.join(root_dir, subset)\n",
    "        if not os.path.exists(subset_dir):\n",
    "            os.makedirs(subset_dir)\n",
    "    \n",
    "        for class_name in classes:\n",
    "            class_dir = os.path.join(subset_dir, class_name)\n",
    "            if not os.path.exists(class_dir):\n",
    "                os.makedirs(class_dir)\n",
    "            \n",
    "            source_videos = source_slip_videos if class_name == 'slip' else source_wriggle_videos\n",
    "            video_files = [f for f in os.listdir(source_videos) if f.endswith('.avi')]\n",
    "            random.shuffle(video_files)  # Shuffle video files\n",
    "            \n",
    "            split_ratio = split_ratios[subsets.index(subset)]\n",
    "            num_videos = int(len(video_files) * split_ratio)\n",
    "            \n",
    "            for video_file in video_files[:num_videos]:\n",
    "                src_path = os.path.join(source_videos, video_file)\n",
    "                dest_path = os.path.join(class_dir, video_file)\n",
    "                shutil.copy(src_path, dest_path)\n",
    "    \n",
    "    print(\"Directory structure and video copying completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ead1f-11a8-4f7e-a37c-17cf478e7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8134ce-3049-4fc1-b37c-467f55dfd51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.videos = self._load_videos()\n",
    "        self.transform = transform\n",
    "\n",
    "    def _load_videos(self):\n",
    "        videos = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            for video_file in os.listdir(class_dir):\n",
    "                if video_file.endswith('.avi'):\n",
    "                    video_path = os.path.join(class_dir, video_file)\n",
    "                    videos.append((video_path, self.class_to_idx[class_name]))\n",
    "        return videos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_path, label = self.videos[idx]\n",
    "\n",
    "        video = imageio.get_reader(video_path, 'ffmpeg')  # Open video with imageio\n",
    "        \n",
    "        #print(\"Video:\", video_path)\n",
    "        #print(\"Number of frames:\", len(video))\n",
    "        #print(\"Height:\", video.get_meta_data()[\"size\"][1])\n",
    "        #print(\"Width:\", video.get_meta_data()[\"size\"][0])\n",
    "        \n",
    "        \n",
    "        frames = []\n",
    "        \n",
    "        for frame in video:\n",
    "            frame = frame[:, :, :3]  # Keep only the first three channels (RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "        video.close()\n",
    "        \n",
    "        #container = av.open(video_path)  # Open the video file with pyav\n",
    "        #frames = []\n",
    "        #for frame in container.decode(video=0):  # Loop through video frames\n",
    "        #    img = frame.to_image()\n",
    "        #    img = img.convert('RGB')  # Convert to RGB format\n",
    "        #    frame_array = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).view(img.size[1], img.size[0], 3)\n",
    "        #    frames.append(frame_array.numpy())\n",
    "        \n",
    "        #container.close() \n",
    "        \n",
    "        if self.transform:\n",
    "            frames = [self.transform(frame) for frame in frames]\n",
    "            video_tensor = torch.stack(frames)\n",
    "        #print(video_tensor.shape)\n",
    "        return video_tensor.permute(1, 0, 2, 3), label  # Permute to (batch, channels, frames, height, width)\n",
    "\n",
    "data_transform = Compose([\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078f1a46-2922-4f01-8a38-0c290f40d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './dataset'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "val_dir = os.path.join(root_dir, 'validation')\n",
    "test_dir = os.path.join(root_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65a7814-748b-4cd3-9f45-87883c04bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(train_dir, transform=data_transform)\n",
    "val_dataset = VideoDataset(val_dir, transform=data_transform)\n",
    "test_dataset = VideoDataset(test_dir, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96acecb9-7ceb-4df0-af6d-254ab5497d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0,shuffle=True)\n",
    "#test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3e3fe5c-89a2-4f5f-8096-2289da9be828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage of the DataLoader\n",
    "#for videos, labels in train_loader:\n",
    "    # videos will have the shape: (batch, channels, frames, height, width)\n",
    "#    print(\"Video batch shape:\", videos.shape)\n",
    "#    print(\"Label batch:\", labels)\n",
    "#    break  # Stop after the first batch for demonstration purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "421dddbb-ae57-470e-b5a8-2f38938ade44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['slip', 'wriggle']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2c8f8-2163-4e30-8938-50d0197e9686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
